{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fabric APIs\n",
    "This notebook is an example of how to use a lot of the APIs in OneLake (ADLSGen2) and Fabric and Azure Management. I will try to keep these up-to-date with others. I just like having an example of everything in one place ðŸ˜€\n",
    "\n",
    "[OneLake](#onelake-apis)\n",
    "\n",
    "[Upload a File](#upload-a-file)\n",
    "\n",
    "[Load File to Table](#load-file-to-table-with-lakehouse-api)\n",
    "\n",
    "[Query Table](#call-sql-endpoint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "import requests\n",
    "import json,os\n",
    "import struct\n",
    "from itertools import chain, repeat\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Credentials for Future Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = DefaultAzureCredential() \n",
    "\n",
    "# Fabric token\n",
    "fabric_token=credential.get_token('https://api.fabric.microsoft.com/.default')\n",
    "fabric_headers={'Authorization': 'Bearer ' + fabric_token.token, 'Content-Type': 'application/json'}\n",
    "\n",
    "# Storage token\n",
    "onelake_token=credential.get_token('https://storage.azure.com/.default')\n",
    "onelake_headers={'Authorization': 'Bearer ' + onelake_token.token, 'Content-Type': 'application/json'}\n",
    "\n",
    "database_token = credential.get_token(\"https://database.windows.net/.default\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# CHANGE THESE TO YOUR OWN: Setup the variables for the workspace and lakehouse\n",
    "workspaceName=\"fabricit\"\n",
    "lakehouseName=\"mslearn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Workspace ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the old Power BI API to get the workspace ID\n",
    "# NOTE: This is on the roadmap to provide search \n",
    "# - https://learn.microsoft.com/en-us/fabric/release-plan/shared-experiences#workspace-filters-search-support-nested-folders\n",
    "response = requests.get(f\"https://api.powerbi.com/v1.0/myorg/groups?$filter=tolower(name) eq tolower('{workspaceName}')\", headers=fabric_headers)\n",
    "# response = requests.get(f\"https://api.powerbi.com/v1.0/myorg/groups?$filter=startswith(name,'{workspaceName}')\", headers=fabric_headers)\n",
    "# response = requests.get(\"https://api.powerbi.com/v1.0/myorg/groups\", headers=fabric_headers)\n",
    "\n",
    "if 200 == response.status_code:\n",
    "    values=response.json()['value']\n",
    "    if len(values)==1:\n",
    "        workspaceId=values[0]['id']\n",
    "        print(\"workspaceId\",workspaceId)\n",
    "    else:\n",
    "        print(\"Workspace not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Lakehouse ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = requests.get(\"https://api.fabric.microsoft.com/v1/workspaces?$filter=contains(displayName,'fabricit')\", headers=fabric_headers)\n",
    "response = requests.get(f\"https://api.fabric.microsoft.com/v1/workspaces/{workspaceId}/Lakehouses\", headers=fabric_headers)\n",
    "print(response.status_code)\n",
    "# Grab the one that matches the name of lakehouseName\n",
    "if 200 == response.status_code:\n",
    "    for lakehouse in response.json()['value']:\n",
    "        # case insensitive comparison\n",
    "        if lakehouse['displayName'].lower() == lakehouseName.lower():\n",
    "            lakehouseId = lakehouse['id']\n",
    "            print(\"lakehouseId\",lakehouseId)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneLake APIs\n",
    "You can access by either the names or the GUIDs. HOWEVER, you cannot have spaces in the workspace (aka Container) or it won't work at all by name\n",
    "\n",
    "> NOTE: If you access by names, you can't interchange GUID and Names\n",
    "\n",
    "References:\n",
    "- https://learn.microsoft.com/en-us/fabric/onelake/onelake-access-python\n",
    "- https://learn.microsoft.com/en-us/fabric/onelake/onelake-access-api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Items by Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get items by the name of the workspace\n",
    "requests.get(f\"https://onelake.dfs.fabric.microsoft.com/{workspaceName}?resource=filesystem&recursive=false\", headers=onelake_headers).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Items by GUID\n",
    "> NOTE: See the changes in the response are GUIDs and not names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get items by the name of the workspace\n",
    "requests.get(f\"https://onelake.dfs.fabric.microsoft.com/{workspaceId}?resource=filesystem&recursive=false\", headers=onelake_headers).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the demo.csv file to OneLake\n",
    "url = f\"https://onelake.dfs.fabric.microsoft.com/{workspaceId}/{lakehouseId}/Files/demo.csv\"\n",
    "\n",
    "headers=onelake_headers.copy()\n",
    "headers['Content-Length']=\"0\"\n",
    "\n",
    "with open('demo.csv', 'rb') as f:\n",
    "    response = requests.put(url, headers=headers, params={'resource': 'file'})\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 201:\n",
    "    print(\"File creation successful\")\n",
    "else:\n",
    "    print(\"File creation failed:\", response.text)\n",
    "\n",
    "# Upload the data\n",
    "headers=onelake_headers.copy()\n",
    "headers['Content-Length'] = str(os.path.getsize('demo.csv'))  # Set the Content-Length to the size of the file\n",
    "with open('demo.csv', 'rb') as f:\n",
    "    response = requests.patch(url, headers=headers, data=f, params={'action': 'append', 'position': '0'})\n",
    "\n",
    "if response.status_code == 202:\n",
    "    print(\"Data upload successful\")\n",
    "else:\n",
    "    print(\"Data upload failed:\", response.text)\n",
    "\n",
    "# Flush the data\n",
    "headers=onelake_headers.copy()\n",
    "headers['Content-Length'] = \"0\"\n",
    "response = requests.patch(url, headers=headers, params={'action': 'flush', 'position': str(os.path.getsize('demo.csv'))})\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Data flush successful\")\n",
    "else:\n",
    "    print(\"Data flush failed:\", response.text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get items by the name of the workspace\n",
    "requests.get(f\"https://onelake.dfs.fabric.microsoft.com/{workspaceName}/{lakehouseName}.Lakehouse/Files?resource=filesystem&recursive=false\", headers=onelake_headers).json()\n",
    "\n",
    "# Get the file properties only\n",
    "resp=requests.head(f\"https://onelake.dfs.fabric.microsoft.com/{workspaceName}/{lakehouseName}.Lakehouse/Files/demo.csv?resource=file\", headers=onelake_headers)\n",
    "print(resp.status_code)\n",
    "print(resp.headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the actual file\n",
    "resp=requests.get(f\"https://onelake.dfs.fabric.microsoft.com/{workspaceName}/{lakehouseName}.Lakehouse/Files/demo.csv\", headers=onelake_headers)\n",
    "print(resp.status_code)\n",
    "# Check if the request was successful\n",
    "if resp.status_code == 200:\n",
    "    # Write the content to a file\n",
    "    with open('demo_download.csv', 'wb') as f:\n",
    "        f.write(resp.content)\n",
    "    print(\"File downloaded successfully\")\n",
    "else:\n",
    "    print(\"File download failed:\", resp.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load File to Table with Lakehouse API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Table from File\n",
    "body = { \n",
    "  \"relativePath\": \"Files/demo.csv\", \n",
    "  \"pathType\": \"File\", \n",
    "  \"mode\": \"overwrite\", \n",
    "  \"recursive\": False,\n",
    "  \"formatOptions\": \n",
    "  { \n",
    "    \"header\": True, \n",
    "    \"delimiter\": \",\", \n",
    "    \"format\": \"CSV\" \n",
    "  } \n",
    "}\n",
    "response = requests.post(f\"https://api.fabric.microsoft.com/v1/workspaces/{workspaceId}/lakehouses/{lakehouseId}/tables/demo/load\", headers=fabric_headers, json=body)\n",
    "print(response.status_code)\n",
    "\n",
    "if 202 == response.status_code:\n",
    "    print(\"Table load started\")\n",
    "    response.headers[\"Location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of the load\n",
    "url = response.headers[\"Location\"]\n",
    "response = requests.get(url, headers=fabric_headers)\n",
    "print(response.status_code)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get items by the name of the workspace\n",
    "requests.get(f\"https://onelake.dfs.fabric.microsoft.com/{workspaceName}/{lakehouseName}.Lakehouse/Files?resource=filesystem&recursive=false\", headers=onelake_headers).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fabric REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the properties of a Workspace\n",
    "requests.get(f\"https://api.fabric.microsoft.com/v1/workspaces/{workspaceId}\", headers=fabric_headers).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Lakehouses in a Workspace\n",
    "requests.get(f\"https://api.fabric.microsoft.com/v1/workspaces/{workspaceId}/Lakehouses\", headers=fabric_headers).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call SQL Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lakehouse\n",
    "resp = requests.get(f\"https://api.fabric.microsoft.com/v1/workspaces/{workspaceId}/Lakehouses/{lakehouseId}\", headers=fabric_headers).json()\n",
    "# print(json.dumps(resp, indent=2))\n",
    "\n",
    "lakehouseEndpoint = resp['properties']['sqlEndpointProperties']['connectionString']\n",
    "databaseName=resp['displayName']\n",
    "\n",
    "# Load of credentials and execute the code\n",
    "\n",
    "credential = DefaultAzureCredential() \n",
    "sql_endpoint = lakehouseEndpoint \n",
    "database = databaseName \n",
    "\n",
    "connection_string = f\"Driver={{ODBC Driver 18 for SQL Server}};Server={sql_endpoint},1433;Database=f{database};Encrypt=Yes;TrustServerCertificate=No\"\n",
    "\n",
    "# Convert the token to a UTF-8 byte string\n",
    "token_as_bytes = bytes(database_token.token, \"UTF-8\") \n",
    "# Encode the bytes to a Windows byte string\n",
    "encoded_bytes = bytes(chain.from_iterable(zip(token_as_bytes, repeat(0)))) \n",
    "# Package the token into a bytes object\n",
    "token_bytes = struct.pack(\"<i\", len(encoded_bytes)) + encoded_bytes \n",
    "# Attribute pointing to SQL_COPT_SS_ACCESS_TOKEN to pass access token to the driver\n",
    "attrs_before = {1256: token_bytes}  \n",
    "\n",
    "connection = pyodbc.connect(connection_string, attrs_before=attrs_before)\n",
    "cursor = connection.cursor()\n",
    "# cursor.execute(\"SELECT * FROM sys.tables\")\n",
    "cursor.execute(f\"SELECT * FROM {lakehouseName}.dbo.demo\")\n",
    "rows = cursor.fetchall()\n",
    "print(rows)\n",
    "\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Access Roles\n",
    "https://learn.microsoft.com/en-us/fabric/onelake/security/get-started-data-access-roles\n",
    "- You must opt in on the Lakehouse for these permissions\n",
    "\n",
    "https://blog.fabric.microsoft.com/en-us/blog/onelake-data-access-roles-apis-announcement\n",
    "\n",
    "https://learn.microsoft.com/en-us/rest/api/fabric/core/onelake-data-access-security/list-data-access-roles?tabs=HTTP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(f\"https://api.fabric.microsoft.com/v1/workspaces/{workspaceId}/items/{lakehouseId}/dataAccessRoles\", headers=fabric_headers).json()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai102",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
