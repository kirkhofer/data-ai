{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper\n",
    "Get started quickly with this notebook and references. I am hoping there are other REST API updates made because using multipart is so ugly.\n",
    "\n",
    "1. Make sure you have an Azure OpenAI account\n",
    "2. Create a deployment named `whisper` in `North Central US` or `Western Europe` (I am sure more will come on like soon)\n",
    "3. Make sure you have the keys and endpoints store in a `.env` file\n",
    "    ```bash\n",
    "    WHISPER_AOAI_ENDPOINT=https://{resource name}.openai.azure.com/\n",
    "    WHISPER_AOAI_KEY=999999\n",
    "    ```\n",
    "\n",
    "## References\n",
    "- https://techcommunity.microsoft.com/t5/azure-ai-services-blog/announcing-the-preview-of-openai-whisper-in-azure-openai-service/ba-p/3928388\n",
    "- https://learn.microsoft.com/en-us/azure/ai-services/speech-service/whisper-overview\n",
    "- https://learn.microsoft.com/en-us/azure/ai-services/openai/whisper-quickstart?tabs=command-line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "\n",
    "load_dotenv(\".env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_file(audioUrl):\n",
    "    response = requests.get(audioUrl)\n",
    "    with open('File.wav', 'wb') as file:\n",
    "        file.write(response.content)    \n",
    "\n",
    "    headers={}\n",
    "    headers['api-key']=os.getenv('WHISPER_AOAI_KEY')\n",
    "    endpoint=os.getenv('WHISPER_AOAI_ENDPOINT')\n",
    "    files = {\n",
    "        'file': ('File.wav', open('File.wav', 'rb')),\n",
    "    }\n",
    "    url=f\"{endpoint}openai/deployments/whisper/audio/transcriptions?api-version=2023-09-01-preview\"\n",
    "    response=requests.post(url,files=files,headers=headers)\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and run some audio files through. You can use examples from this site https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/sampledata/audiofiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\":\"The ocelot, Lepardus paradalis, is a small wild cat native to the southwestern United States, Mexico, and Central and South America. This medium-sized cat is characterized by solid black spots and streaks on its coat, round ears, and white neck and undersides. It weighs between 8 and 15.5 kilograms, 18 and 34 pounds, and reaches 40 to 50 centimeters – 16 to 20 inches – at the shoulders. It was first described by Carl Linnaeus in 1758. Two subspecies are recognized, L. p. paradalis and L. p. mitis. Typically active during twilight and at night, the ocelot tends to be solitary and territorial. It is efficient at climbing, leaping, and swimming. It preys on small terrestrial mammals such as armadillo, opossum, and lagomorphs.\"}\n"
     ]
    }
   ],
   "source": [
    "run_file('https://github.com/Azure-Samples/cognitive-services-speech-sdk/raw/master/sampledata/audiofiles/wikipediaOcelot.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\":\"What is the speech services? The speech service is the unification of speech text, text-to-speech, and speech translation into a single Azure subscription. It is easy to speech enable your applications, tools, and devices with the speech SDK, speech devices SDK, and the restful APIs. These features made up the speech services. Use the links in this table to learn more about common use cases for each feature or browse the API references. Speech-to-text transcribes or translates audio streams or local files to text in real-time that your applications, tools, or devices can consume or display. Use speech-to-text with language understanding to derive user intent from the transcribed speech and act on voice commands.\"}\n"
     ]
    }
   ],
   "source": [
    "run_file('https://github.com/Azure-Samples/cognitive-services-speech-sdk/raw/master/sampledata/audiofiles/speechService.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai102",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
