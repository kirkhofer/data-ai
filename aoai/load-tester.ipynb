{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Tester\n",
    "Similar to the one in PowerShell, this one executes calls against Azure OpenAI endpoints to test the performance of the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "from deployments import *\n",
    "import collections as collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Deployments\n",
    "> NOTE: You may want to store these so it doesn't have to do this everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-21 10:43:45\n",
      "Running aoai-dai-dev-ncus\n",
      "Running aoai-dai-dev-fc\n",
      "Running aoai-dai-dev-ce\n",
      "Running aoai-dai-dev-gwc\n",
      "Running aoai-dai-dev-use\n",
      "Running aoai-dai-dev-ae\n",
      "Running aoai-dai-dev-sn\n",
      "Running aoai-dai-dev-scus\n",
      "Running aoai-dai-dev-sc\n",
      "Running aoai-dai-dev-usw3\n",
      "Running aoai-dai-dev-we\n",
      "Running aoai-dai-dev-ne\n",
      "Running aoai-dai-dev-use2\n",
      "Running aoai-dai-dev-uks\n",
      "GlobalBatch Deployments Deleted 0\n"
     ]
    }
   ],
   "source": [
    "# Get all the deployments in my subscription\n",
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "deployments = get_deployments()\n",
    "\n",
    "# Print the number of deployments\n",
    "nDeps=len(deployments)\n",
    "\n",
    "# Remove the deployments where skuName is \"GlobalBatch\"\n",
    "deployments = [deployment for deployment in deployments if deployment['skuName'] != 'GlobalBatch']\n",
    "\n",
    "print(\"GlobalBatch Deployments Deleted\",nDeps-len(deployments))\n",
    "\n",
    "# Save the deployments to a file in local/deployments.json\n",
    "# with open('local/deploymentsFull.json', 'w') as f:\n",
    "#     json.dump(deployments, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chat(deployments,data,timeout=60):\n",
    "    deployment = deployments[random.randint(0,len(deployments)-1)]\n",
    "    headers={\"Content-Type\":\"application/json\",\"api-key\":deployment[\"key\"]}\n",
    "    url=f\"{deployment['endpoint']}openai/deployments/{deployment['deploymentName']}/chat/completions?api-version=2024-06-01\"\n",
    "\n",
    "    status_code=None\n",
    "    timeSpan=0\n",
    "    detail=None\n",
    "    region=None\n",
    "    total_tokens=0\n",
    "    resp_headers={}\n",
    "    finish_reason=None\n",
    "\n",
    "    try:\n",
    "        startTime=time.time()\n",
    "        response=requests.post(url=url,json=data,headers=headers,timeout=timeout)\n",
    "        endTime=time.time()\n",
    "\n",
    "        status_code=response.status_code\n",
    "        timeSpan=endTime-startTime\n",
    "\n",
    "        region=None\n",
    "        if response.status_code == 200:\n",
    "            region=response.headers[\"x-ms-region\"]\n",
    "            finish_reason=response.json().get('choices', [])[0].get('finish_reason',None)\n",
    "            if finish_reason == \"content_filter\":\n",
    "                detail=response.json().get('choices', [])[0].get('content_filter_results', {}) if response.status_code == 200 else None\n",
    "            else:\n",
    "                detail=response.json().get('choices', [])[0].get('message', {}).get('content',None) if response.status_code == 200 else None\n",
    "        else:\n",
    "            detail=response.json()\n",
    "        \n",
    "        total_tokens=response.json().get('usage', {}).get('total_tokens', 0) if response.status_code == 200 else 0\n",
    "        resp_headers=response.headers\n",
    "    except Exception as e:\n",
    "        if hasattr(e, 'status_code'):\n",
    "            status_code=e.status_code\n",
    "        detail=str(e)\n",
    "        if hasattr(e, 'response'):\n",
    "            detail= e.response.json()['error']['message']\n",
    "        finish_reason=\"Exception\"\n",
    "\n",
    "    return {\n",
    "            \"status_code\":status_code,\n",
    "            \"response\":detail,\n",
    "            \"timeSpan\":timeSpan,\n",
    "            \"region\":region,\n",
    "            \"endpoint\":deployment['endpoint'],\n",
    "            \"deploymentName\":deployment['deploymentName'],\n",
    "            \"total_tokens\": total_tokens,\n",
    "            \"headers\":resp_headers,\n",
    "            \"finish_reason\":finish_reason\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployments to test: 4\n"
     ]
    }
   ],
   "source": [
    "# Narrow down which deployments you want to test\n",
    "\n",
    "# enabled=([d for d in deployments if d['model'] == 'gpt-35-turbo' and d['version'] == \"0125\" and d['location'] == \"northcentralus\"])\n",
    "# enabled=([d for d in deployments if d['model'] == 'gpt-35-turbo' and d['version'] == \"0613\" and d['location'] == \"northcentralus\"])\n",
    "# enabled=([d for d in deployments if d['model'] == 'gpt-35-turbo' and d['version'] == \"0613\"])\n",
    "# enabled=([d for d in deployments if d['deploymentName'] == 'gpt-4o-hourly'])\n",
    "# enabled=([d for d in deployments if d['model'] == 'gpt-4o'])\n",
    "# enabled=([d for d in deployments if d['deploymentName'] == 'gpt-4o'])\n",
    "enabled=([d for d in deployments if d['model'] == 'gpt-4o' and d['location'] == \"eastus2\" and d['skuName']==\"Standard\"])\n",
    "# enabled=([d for d in deployments if d['model'] == 'gpt-4o-mini'])\n",
    "\n",
    "# enabled=([d for d in deployments if d['deploymentName'] == 'gpt-35-turbo'])\n",
    "\n",
    "print(\"Deployments to test:\",len(enabled))\n",
    "\n",
    "assert len(enabled) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started: 2024-09-21 10:46:41\n",
      "Time taken (sec): 2.9282116889953613\n"
     ]
    }
   ],
   "source": [
    "# How many threads to run\n",
    "threadCnt=3\n",
    "# Total number of tests to run\n",
    "testCnt=10\n",
    "\n",
    "# Give it a file for the body of the message\n",
    "fileName='body-joke.json'\n",
    "\n",
    "# load json file with the data\n",
    "with open(fileName) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Run the tests\n",
    "p=Pool(threadCnt)\n",
    "start = time.time()\n",
    "print(\"Started:\",time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "results = [p.apply_async(run_chat,(enabled,data) ) for i in range(testCnt)]\n",
    "output = [p.get() for p in results]\n",
    "end = time.time()\n",
    "print(\"Time taken (sec):\",end-start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status_code': 200, 'response': 'Why did the scarecrow become a successful motivational speaker?\\n\\nBecause he was outstanding in his field and always knew how to lift peopleâ€™s spirits! ðŸŒ¾âœ¨ðŸ˜„', 'timeSpan': 0.8125629425048828, 'region': 'East US 2', 'endpoint': 'https://aoai-dai-dev-use2.openai.azure.com/', 'deploymentName': 'gpt-4o', 'total_tokens': 47, 'headers': {'Content-Length': '1025', 'Content-Type': 'application/json', 'x-ms-region': 'East US 2', 'apim-request-id': '96af233d-2679-4706-9ee9-37da5653be02', 'x-ratelimit-remaining-requests': '19', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '1a0eafb5-b9d0-4ff6-a40f-80df26d3b554', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'azureml-model-session': 'd070-20240813235024', 'x-content-type-options': 'nosniff', 'x-envoy-upstream-service-time': '469', 'x-ms-client-request-id': '96af233d-2679-4706-9ee9-37da5653be02', 'x-ratelimit-remaining-tokens': '19568', 'Date': 'Sat, 21 Sep 2024 15:45:38 GMT'}, 'finish_reason': 'stop'}\n",
      "Counter({200: 10})\n",
      "Counter({'stop': 10})\n",
      "Time (ms): 4710.362672805786\n",
      "Time (sec): 4.710362672805786\n",
      "% of 200: 100.0\n",
      "% of 429: 0.0\n",
      "Threads: 3\n",
      "Messages: 10\n",
      "Total Tokens: 503\n",
      "Average TimeSpan (sec): 1.3282943725585938\n"
     ]
    }
   ],
   "source": [
    "print(output[0])\n",
    "\n",
    "ct = collection.Counter([each_result['status_code'] for each_result in output])\n",
    "output_200 = ct[200]\n",
    "output_429 = ct[429]\n",
    "print(ct)\n",
    "\n",
    "cf = collection.Counter([each_result['finish_reason'] for each_result in output])\n",
    "print(cf)\n",
    "\n",
    "\n",
    "total_time=(end-start) * 10**3\n",
    "print(\"Time (ms):\",total_time)\n",
    "print(\"Time (sec):\",(end-start))\n",
    "print(\"% of 200:\", (output_200 / len(output)) * 100)\n",
    "print(\"% of 429:\",((output_429)/len(output)) * 100)\n",
    "print(\"Threads:\",threadCnt)\n",
    "print(\"Messages:\",testCnt)\n",
    "print(\"Total Tokens:\",sum([item['total_tokens'] for item in output if item['status_code'] == 200]))\n",
    "\n",
    "# Extract the timeSpan values from the output list\n",
    "time_spans = [each_result['timeSpan'] for each_result in output]\n",
    "\n",
    "# Compute the average timeSpan\n",
    "average_time_span = sum(time_spans) / len(time_spans)\n",
    "\n",
    "print(\"Average TimeSpan (sec):\", average_time_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through output and write a row in a text file with a tab separated format\n",
    "with open('output.txt', 'w') as f:\n",
    "    for each_result in output:\n",
    "        f.write(f\"{fileName}\\t{threadCnt}\\t{testCnt}\\t{each_result['status_code']}\\t{each_result['timeSpan']}\\t{each_result['region']}\\t{each_result['endpoint']}\\t{each_result['deploymentName']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first 10 items in the output list where the status_code is 200\n",
    "\n",
    "for item in output[:10]:\n",
    "    print(\"endpoint:\",item['endpoint'])\n",
    "    print(\"deploymentName:\",item['deploymentName'])\n",
    "    if item['status_code'] == 200:\n",
    "        print(\"response:\",item['response'])\n",
    "        print(\"total_tokens:\",item['total_tokens'])\n",
    "        print(\"timeSpan:\",item['timeSpan'])\n",
    "        print(\"region:\",item['region'])\n",
    "    else:\n",
    "        print(item['status_code'])\n",
    "        print(item['response'])\n",
    "    if item['headers']:\n",
    "        print('x-ratelimit-remaining-requests',item['headers'].get('x-ratelimit-remaining-requests',None))\n",
    "        print('x-ratelimit-remaining-tokens',item['headers'].get('x-ratelimit-remaining-tokens',None))\n",
    "    print(\"-\" * 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai102",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
