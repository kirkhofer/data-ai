{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Get Configuration Settings\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_type = 'azure'\n",
    "openai.api_key = os.getenv('AOAI_KEY')\n",
    "openai.api_base =  os.getenv('AOAI_ENDPOINT') \n",
    "openai.api_version = os.environ.get(\"AOAI_VERSION\",\"2023-03-15-preview\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=\"gpt-35-turbo\", # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What's the difference between garbanzo beans and chickpeas?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I'm sorry, but as an AI language model, I am incapable of predicting the future. However, the 2022 World Series has not yet occurred, as it is an upcoming event. Once the championship is held, I'm sure sports news outlets will be excited to report on the winner.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "\n",
    "while(True):\n",
    "    user_input = input()      \n",
    "    if user_input == \"exit\" or user_input == \"quit\" or user_input == \"\":\n",
    "        break\n",
    "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=\"gpt-35-turbo\", # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "        messages = conversation\n",
    "    )\n",
    "\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": response['choices'][0]['message']['content']})\n",
    "    print(\"\\n\" + response['choices'][0]['message']['content'] + \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bot for reading content from a web site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=input(\"Enter a url for a web site\")\n",
    "conversation=[{\"role\": \"system\", \"content\": f\"You are a helpful assistant that knows alot about {url}. Read the webside and answer questions.\"}]\n",
    "\n",
    "while(True):\n",
    "    user_input = input()      \n",
    "    if user_input == \"exit\" or user_input == \"quit\" or user_input == \"\":\n",
    "        break\n",
    "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=\"gpt-35-turbo\", # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "        messages = conversation\n",
    "    )\n",
    "\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": response['choices'][0]['message']['content']})\n",
    "    print(\"\\n\" + response['choices'][0]['message']['content'] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"The CSS code for a color like a blue sky at dusk:\n",
    "\n",
    "background-color: #\"\"\"\n",
    "response=openai.Completion.create(prompt=prompt,\n",
    "    engine='text-davinci-003',\n",
    "    max_tokens=64, \n",
    "    temperature=0, \n",
    "    top_p=1, \n",
    "    frequency_penalty=0.0, \n",
    "    presence_penalty=0.0, \n",
    "    stop=[\";\"])\n",
    "\n",
    "print(f\"{response.choices[0].text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"Write a tagline for an ice cream shop.\"\n",
    "response=openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    engine='text-davinci-003'\n",
    ")\n",
    "\n",
    "print(f\"{response.choices[0].text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "The following is a list of companies and the categories they fall into:\n",
    "\n",
    "Apple, Facebook, Fedex\n",
    "\n",
    "Apple\n",
    "Category:\n",
    "\"\"\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine='text-davinci-003',\n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=64,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "\n",
    "print(f\"{response.choices[0].text}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All about SQL Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    d.name\n",
      "FROM\n",
      "    Department d\n",
      "    INNER JOIN Employee e ON d.id = e.department_id\n",
      "    INNER JOIN Salary_Payments sp ON e.id = sp.employee_id\n",
      "WHERE\n",
      "    sp.date > NOW() - INTERVAL '3 months'\n",
      "GROUP BY\n",
      "    d.name\n",
      "HAVING\n",
      "    COUNT(e.id) > 10\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"\n",
    "### Postgres SQL tables, with their properties:\n",
    "#\n",
    "# Employee(id, name, department_id)\n",
    "# Department(id, name, address)\n",
    "# Salary_Payments(id, employee_id, amount, date)\n",
    "#\n",
    "#Create a SQL query for A query to list the names of the departments which employed more than 10 employees in the last 3 months\n",
    "SELECT\n",
    "\"\"\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine='code-davinci-002',\n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=150,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "    stop=[\"#\",\";\"]\n",
    ")\n",
    "\n",
    "print(f\"{response.choices[0].text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bot to write SQL for multiple questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(*) FROM Department\n",
      "\n",
      "SELECT department.name, COUNT(employee.id)\n",
      "FROM employee\n",
      "INNER JOIN department ON employee.department_id = department.id\n",
      "GROUP BY department.name\n",
      "\n",
      "\n",
      "\n",
      "SELECT department.name, COUNT(employee.id) AS employee_count\n",
      "FROM employee\n",
      "JOIN department ON employee.department_id = department.id\n",
      "GROUP BY department.name\n",
      "ORDER BY employee_count DESC\n",
      "LIMIT 3\n"
     ]
    }
   ],
   "source": [
    "# Same thing but will ONLY generate the SQL statement\n",
    "prompt=\"\"\"\n",
    "Postgres SQL tables, with their properties:\n",
    "Employee(id, name, department_id)\n",
    "Department(id, name, address)\n",
    "Salary_Payments(id, employee_id, amount, date)\n",
    "\n",
    "#Create a SQL query for \"{0}\"\n",
    "\"\"\"\n",
    "\n",
    "while(True):\n",
    "    user_input = input()      \n",
    "    if user_input == \"exit\" or user_input == \"quit\" or user_input == \"\":\n",
    "        break\n",
    "\n",
    "    sql = prompt.format(user_input)\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "    engine='code-davinci-002',\n",
    "    prompt=sql,\n",
    "    temperature=0,\n",
    "    max_tokens=150,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    "      stop=[\"#\",\";\"]\n",
    "    )\n",
    "\n",
    "    print(f\"{response.choices[0].text}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This using GPT model and gets more conversational\n",
    "Do you like the conversation? You can easily parse the SQL returned with LangChain or other coding to then turnaround and execute the SQL for the end users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I'm sorry, I didn't understand your request. Can you please provide more information on what you need?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chat SQL with ChatGPT\n",
    "prompt=\"\"\"\n",
    "Tables and columns:\n",
    "Employee(id, name, department_id)\n",
    "Department(id, name, address)\n",
    "Salary_Payments(id, employee_id, amount, date)\n",
    "\n",
    "You are a bot that generates SQL code based on the \"Tables and columns\". Return standard SQL queries that a user could then run in a tool like SQL Server Management Studio\n",
    "\"\"\"\n",
    "\n",
    "conversation=[{\"role\": \"system\", \"content\": prompt}]\n",
    "\n",
    "while(True):\n",
    "    user_input = input()      \n",
    "    if user_input == \"exit\" or user_input == \"quit\" or user_input == \"\":\n",
    "        break\n",
    "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=\"gpt-35-turbo\", # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "        messages = conversation\n",
    "    )\n",
    "\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": response['choices'][0]['message']['content']})\n",
    "    print(\"\\n\" + response['choices'][0]['message']['content'] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I'm sorry, but as an AI language model, I am incapable of predicting the future. However, the 2022 World Series has not yet occurred, as it is an upcoming event. Once the championship is held, I'm sure sports news outlets will be excited to report on the winner.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "\n",
    "while(True):\n",
    "    user_input = input()      \n",
    "    if user_input == \"exit\" or user_input == \"quit\" or user_input == \"\":\n",
    "        break\n",
    "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=\"gpt-35-turbo\", # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "        messages = conversation\n",
    "    )\n",
    "\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": response['choices'][0]['message']['content']})\n",
    "    print(\"\\n\" + response['choices'][0]['message']['content'] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "Convert movie titles into emoji.\n",
    "\n",
    "Back to the Future: 👨👴🚗🕒 \n",
    "Batman: 🤵🦇 \n",
    "Transformers: 🚗🤖 \n",
    "Star Wars:\n",
    "\"\"\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine='text-davinci-003',\n",
    "  prompt=prompt,\n",
    "  temperature=0.8,\n",
    "  max_tokens=60,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "print(f\"{response.choices[0].text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "class Log:\n",
    "    def __init__(self, path):\n",
    "        dirname = os.path.dirname(path)\n",
    "        os.makedirs(dirname, exist_ok=True)\n",
    "        f = open(path, \"a+\")\n",
    "\n",
    "        # Check that the file is newline-terminated\n",
    "        size = os.path.getsize(path)\n",
    "        if size > 0:\n",
    "            f.seek(size - 1)\n",
    "            end = f.read(1)\n",
    "            if end != \"\\n\":\n",
    "                f.write(\"\\n\")\n",
    "        self.f = f\n",
    "        self.path = path\n",
    "\n",
    "    def log(self, event):\n",
    "        event[\"_event_id\"] = str(uuid.uuid4())\n",
    "        json.dump(event, self.f)\n",
    "        self.f.write(\"\\n\")\n",
    "\n",
    "    def state(self):\n",
    "        state = {\"complete\": set(), \"last\": None}\n",
    "        for line in open(self.path):\n",
    "            event = json.loads(line)\n",
    "            if event[\"type\"] == \"submit\" and event[\"success\"]:\n",
    "                state[\"complete\"].add(event[\"id\"])\n",
    "                state[\"last\"] = event\n",
    "        return state\n",
    "\n",
    "#\n",
    "Here's what the above class is doing:\n",
    "1.\n",
    "\"\"\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine='code-davinci-002',\n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=64,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"#\"]\n",
    ")\n",
    "\n",
    "print(f\"{response.choices[0].text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "Q: Who is Batman?\n",
    "A: Batman is a fictional comic book character.\n",
    "\n",
    "Q: What is torsalplexity?\n",
    "A: ?\n",
    "\n",
    "Q: What is Devz9?\n",
    "A: ?\n",
    "\n",
    "Q: Who is George Lucas?\n",
    "A: George Lucas is American film director and producer famous for creating Star Wars.\n",
    "\n",
    "Q: What is the capital of California?\n",
    "A: Sacramento.\n",
    "\n",
    "Q: What orbits the Earth?\n",
    "A: The Moon.\n",
    "\n",
    "Q: Who is Fred Rickerson?\n",
    "A: ?\n",
    "\n",
    "Q: What is an atom?\n",
    "A: An atom is a tiny particle that makes up everything.\n",
    "\n",
    "Q: Who is Alvan Muntz?\n",
    "A: ?\n",
    "\n",
    "Q: What is Kozar-09?\n",
    "A: ?\n",
    "\n",
    "Q: How many moons does Mars have?\n",
    "A: Two, Phobos and Deimos.\n",
    "\n",
    "Q: What's a language model?\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine='text-davinci-003',\n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=60,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "\n",
    "print(f\"{response.choices[0].text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "##### Fix bugs in the below function\n",
    " \n",
    "### Buggy Python\n",
    "import Random\n",
    "a = random.randint(1,12)\n",
    "b = random.randint(1,12)\n",
    "for i in range(10):\n",
    "    question = \"What is \"+a+\" x \"+b+\"? \"\n",
    "    answer = input(question)\n",
    "    if answer = a*b\n",
    "        print (Well done!)\n",
    "    else:\n",
    "        print(\"No.\")\n",
    "    \n",
    "### Fixed Python\n",
    "\"\"\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine='code-davinci-002',\n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=182,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"###\"]\n",
    ")\n",
    "\n",
    "print(f\"{response.choices[0].text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "You: How do I combine arrays?\n",
    "JavaScript chatbot: You can use the concat() method.\n",
    "You: How do you make an alert appear after 10 seconds?\n",
    "JavaScript chatbot\n",
    "\"\"\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine='code-davinci-002',\n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=60,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"You:\"]\n",
    ")\n",
    "\n",
    "print(f\"{response.choices[0].text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "Extract the airport codes from this text:\n",
    "\n",
    "Text: \"I want to fly from Los Angeles to Miami.\"\n",
    "Airport codes: LAX, MIA\n",
    "\n",
    "Text: \"I want to fly from Orlando to Boston\"\n",
    "Airport codes:\n",
    "\"\"\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine='text-davinci-003',\n",
    "  prompt=prompt,\n",
    "  max_tokens=60,\n",
    "  temperature=0,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "print(f\"{response.choices[0].text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "You: What have you been up to?\n",
    "Friend: Watching old movies.\n",
    "You: Did you watch anything interesting?\n",
    "Friend:\n",
    "\"\"\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    engine='text-davinci-003',\n",
    "    prompt=prompt,\n",
    "    temperature=0.5,\n",
    "    max_tokens=60,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.5,\n",
    "    presence_penalty=0.0,\n",
    "    stop=[\"You:\"]\n",
    ")\n",
    "\n",
    "print(f\"{response.choices[0].text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "Brainstorm some ideas combining VR and fitness:\n",
    "\"\"\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    engine='text-davinci-003',\n",
    "    prompt=prompt,\n",
    "    temperature=0.6,\n",
    "    max_tokens=150,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=1,\n",
    "    presence_penalty=1\n",
    ")\n",
    "\n",
    "print(f\"{response.choices[0].text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "Create a list of 8 questions for my interview with a science fiction author:\n",
    "\"\"\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    engine='text-davinci-003',\n",
    "    prompt=prompt,\n",
    "    temperature=0.5,\n",
    "    max_tokens=150,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")\n",
    "\n",
    "print(f\"{response.choices[0].text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "Create an outline for an essay about Nikola Tesla and his contributions to technology:\n",
    "\"\"\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    engine='text-davinci-003',\n",
    "    prompt=prompt,\n",
    "    temperature=0.3,\n",
    "    max_tokens=150,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")\n",
    "\n",
    "print(f\"{response.choices[0].text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "What are 5 key points I should know when studying Ancient Rome?\n",
    "\"\"\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    engine='text-davinci-003',\n",
    "    prompt=prompt,\n",
    "    temperature=0.3,\n",
    "    max_tokens=150,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")\n",
    "\n",
    "print(f\"{response.choices[0].text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai102",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
